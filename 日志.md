### 2019.09.15



[TOC]

#### 1. **NMS & IOU 代码**
    ```python
    ## 获得顺序
    order = scores.argsort()[::-1]
    ...
    while order.size > 0:
        i = order[0]
        keep.append(i)
        ...
        ## 比较
        np.maximum(x1[i], x1[order[1:]])
        ...
        detlist = np.where(iou <= thr)[0]
        order = order[detlist + 1]

    ```


#### 2. **直方图均衡**  
   ```python
   ## 图片数组转换
   img = np.asarray(img)
   img = Image.fromarray(img)

   ## 统计灰度级别
   numpix = np.zeros([256])
   ...
   numpix[img[i][j]] += 1

   ## 累积归一化
   sumpix = np.zeros([256])
   ...
   sumpix[i] += sum(propix[:i])

   ## 重新映射  
   new_img = np.empty(img.shape, dtype=np.uint8)
   ...
   new_img[i][j] = 256 * sumpix[img[i][j]]

   ``` 



#### 3. **Guide Achoring**  
**是什么？**    

网络通过训练自动生成 anchor, 包括中心点 x,y 和 长宽 w,h, 无需预设  

**为什么？**   

因为预设的 anchor 尺寸和纵横比是固定的，无法适应极端情况，并且离散的尺寸和纵横比不利于学习，因此考虑让网络自己学习anchor  

**怎么做？**

1. 基于**条件分布**   
    $$p(x,y,w,h|I) = p(x,y|I)p(w,h|x,y,I)$$   

2. **先确定中心点，再预测长宽**  

    - **确定中心点**  
    将feature map 通过 1 x 1 conv + sigmoid, 得到 w x h x 1 的中心点坐标得分

    - **确定长宽**  
    将feature map 通过另一个 1 x 1 conv， 得到 w x h x 2 的长宽dw, dh, 后续需要处理，因为 anchor 是相对于原始图片的:  

        $$
        w = \sigma * s * \exp(dw); h = \sigma * s * \exp(dh); 
        $$    
通过上面两步可以得到 **anchor**  

3. **特征适配**  
    传统情况需要做 ROIpooling 或者 ROIalign 进行尺度统一，但 GA 的 anchor 尺寸在各个位置都不一样，需要调整获得新的**特征图**   

    具体做法是将dw, dh 通过 1 x 1 卷积学习到信息给DeforConv  
    ```python
    offset_channels = kernel_size * kernel_size * 2
    self.conv_offset = nn.Conv2d(
        2, deformable_groups * offset_channels, 1, bias=False)
    ```
**训练**  
- 损失函数加入坐标和长宽loss
- anchor位置训练: feature map 分为物体中心区域(CR), 忽略区域(IR)和外围区域(OR)，将 ground truth 对应在 feature map 上的区域标为物体中心区域，在训练的时候作为正样本，其余区域按照离中心的距离标为忽略或者负样本, FPN中多尺度，优先级 CR > IR > OR
- anchor 尺寸训练
采样了9组尺寸，选取其中最大IoU的尺寸


#### 4. **反向传播 & softmaxloss & 矩阵求导**  
   链式法则和维度匹配


#### 5. **mAP 的理解**
- 定义为PR曲线下的面积，综合Precision和Recall两个指标，评价模型优劣
- 遍历每一个点计算当前Recall下的Precision，注意TP只有一个，FP包含小于阈值和GT的多余框
 - COCO评估在不同的IoU[0.5:0.05:0.95]共10个IoU下的AP，并且在最后以这些阈值下的AP平均作为结果，记为mAP@[0.5, 0.95]
- VOC只评测了IOU=0.5下的AP值。因此相比VOC而言，COCO数据集的评测会更加全面：不仅评估到物体检测模型的分类能力，同时也能体现出检测模型的定位能力



#### 6. **Batch Norm**  
**训练和测试时的区别，以及如何在测试时加速**    
1. 训练的时候是以batch操作，计算方差和均值并滑动平均保留，学习两个参数$\gamma$和$\beta$，而测试阶段是一个样本，用保存的方差和均值测试  
2. 将Conv和BN融合，对卷积核进行一定的缩放，进行加速 
    [链接](https://zhuanlan.zhihu.com/p/48005099)

**为什么能起作用，解决了什么问题**
1. 解决了梯度消失问题
       层与层之间是关联的，但是每一层的数据分布是不一样的，这导致训练困难；并且反向传播过程中梯度的微小改变都将造成蝴蝶效应，所以运用BN将数据分布归一化，加快训练
2. 正则化作用
3. 学习率可以调大  

**不足之处** 

依赖于batchsize，当batchsize过小时，由于方差和均值都是训练阶段基于batchsize得到的（虽然可以滑动平均），不能体现数据的真实分布，导致训练，测试不统一



#### 7. **梯度下降算法VS拟牛顿法**  
- 梯度下降法是一阶导，拟牛顿法是二阶导
- 神经网络是大数据，高维度，非凸的，梯度下降法相比牛顿法更合适
    - 大数据中都是Batch处理，计算梯度（**一阶导**）引入了噪声，牛顿法（**二阶导**）噪声更大
    - 高维下Hessian矩阵计算复杂，而梯度下降是稀疏计算
    - 非凸时Hessian矩阵非正定，容易陷入**鞍点**
- 鞍点  
鞍点是梯度为0，但既不是极大值点也不是极小值点的临界点

#### 8. **解决创建环境时conda版本不匹配问题**  
`./bashrc`和` .bash_profile`区别：  
`./bashrc`每次bash shell被打开时,该文件被读取，` .bash_profile`登录时,该文件仅仅执行一次
```Shell
# 查看 .bashrc 和 .bash_profile
ls -a
# 查看文件大小  
du -h/-b
# 更改后生效
source ~/.bashrc
```

### **2019.09.16**
#### 1. 论文阅读

**《Optical spectrum feature analysis and recognition for optical network security with machine learning》**  

**摘要**  

论文针对侵入信号这一攻击类型，采用支持向量机和一维卷积，分析频谱数据，检测攻击，准确率达到98.54% 和 100% 

**三种攻击**  

窃听(eavesdropping)  
伪装攻击(masquerade attack):伪装成用户获得权限  
干扰攻击(jamming attack):阻止网络工作

**主体思想**

**网络状态隐藏在光学层参数中，** 因此可以通过监视和分析物理层参数和性能来检测物理层攻击。 通过监测物理层参数（本文利用光谱），获得物理层损耗和参数，最后对网络安全环境进行分析，实现未授权信号的检测和识别。  


#### 2.mmdetection相关  
**目标检测学习率设置**  
常用计算方法是：lr = 0.02 / 8 x num_gpus x img_per_gpu / 2

**模型权重加载优先级**  
resume_from > load_from > pretrained   


### **2019.09.17**
#### 1. 决策树
**是什么**？

基于特征对数据进行分类的模型，每次选取**单一特征**进行，可以看作是if-then规则的集合，主要流程分为三个：特征选择，决策树生成，决策树剪枝

**怎么做？**  

- 特征选择  

  ID3: 以信息增益最大化为标准，$G(D,A) = H(D) - H(D|A)$
  
  C4.5: 以信息增益比最大化为标准
  
  CART：分类树以基尼系数最小为标准，回归树以误差平方和最小为标准
  
- 决策树生成

  将所有数据放在根节点，根据评价指标选取特征，直到没有特征可选

- 决策树剪枝

  决策树倾向于正确分类当前数据，泛化能力因此会变弱，剪枝就是为了减轻**过拟合问题**，自底向上处理叶子结点

**为什么?**

- 为什么要信息增益最大

  $H(D|A)$ 是以特征$A$分类时样本的不确定性，为了更好地分类，希望选取$A$特征之后样本的不确定性能够尽可能小，所以采用信息增益最大化

- 为什么信息增益为指标倾向于取值较多地特征

  原因同上

#### 2. FPN中anchor策略和ROIPooling方法　[链接1](https://blog.csdn.net/u012426298/article/details/81516213)  [链接2](https://www.cnblogs.com/hellcat/p/9741213.html)

**是什么**？

目标检测中ROIpooling只用一个尺度的feature map，这导致小目标的ROI很有可能已经消失，FPN提出多尺度feature map，用于ROIpooling，改善了小目标检测性能

**网络结构**

- 自底向上

  网络的正向传播，feature map 逐渐变小，分为$\{$C1, C2, C3, C4, C5$\}$，大小依次减小
  
- 自顶向下

  1. 首先有个细节，$C5$ 首先经过1x1 卷积降维到256，记为$P5$，也作为一个feature map

  2. 横向连接＋上采样，$P5$上采样两倍和C4逐元素相加，产生$P4$，$P3$，$P2$，注意**维度都要保持一致**

  3. 然后对生成的$\{$P5, P4, P3, P2$\}$都要经过一个 3x3 SAME卷积，**去除上采样的混叠影响**
  
  4. $P5$ 做最大池化生成$P6$用于RPN，生成ROI，不用于ROIpooling

**anchor策略**

每个feature map用一种尺度的anchor，但是长宽比还是三种，$\{$P6, P5, P4, P3, P2$\}$对应$\{$512^2^, 256^2^, 128^2^, 64^2^, 32^2^$\}$，注意到**更深的feature map对应更大的anchor**，因为感受野更大，检测更大尺度



**ROIpooling策略**

每个feature map做pooling，ROI根据面积映射公式对应到各自的feature层级，公式如下：
$$
k = [k_{0}+ log_{2}\frac{\sqrt{wh}}{224}]
$$
其中$k~0~=4$，代表层级，$wh$代表ROI面积，面积越大，层级越深

**问题**

1. 如何确定某个 ROI 使用哪一层特征图进行 ROIpooling ?

   公式映射


2. 为什么要所有特征图维度是256?  

   为了参数共享，这样所有层级共享分类层，端到端训练

3. 每个feature map的anchor尺度单一?

   因为有多个feature map，而且anchor是密集滑动

4. 横向连接的作用?  
   
   融合低层位置信息，高分辨率