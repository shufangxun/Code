### 2019.09.15

#### 复习  
1. **NMS & IOU 代码**
    ```python
    ## 获得顺序
    order = scores.argsort()[::-1]
    ...
    while order.size > 0:
        i = order[0]
        keep.append(i)
        ...
        ## 比较
        np.maximum(x1[i], x1[order[1:]])
        ...
        detlist = np.where(iou <= thr)[0]
        order = order[detlist + 1]

    ```
    

2. **直方图均衡**  
   ```python
   ## 图片数组转换
   img = np.asarray(img)
   img = Image.fromarray(img)

   ## 统计灰度级别
   numpix = np.zeros([256])
   ...
   numpix[img[i][j]] += 1

   ## 累积归一化
   sumpix = np.zeros([256])
   ...
   sumpix[i] += sum(propix[:i])

   ## 重新映射  
   new_img = np.empty(img.shape, dtype=np.uint8)
   ...
   new_img[i][j] = 256 * sumpix[img[i][j]]

   ``` 

3. **Guide Achoring**  
    - 是什么？  
      网络通过训练自动生成 anchor, 包括中心点 x,y 和 长宽 w,h, 无需预设
    - 为什么？  
      因为预设的 anchor 尺寸和纵横比是固定的，无法适应极端情况，并且离散的尺寸和纵横比不利于学习，因此考虑让网络自己学习anchor
    - 怎么做？
      - 基于**条件分布**   
        $$p(x,y,w,h|I) = p(x,y|I)p(w,h|x,y,I)$$  
        先确定中心点，再预测长宽
      - 确定中心点 
        将feature map 通过 1 x 1 conv + sigmoid, 得到 w x h x 1 的中心点坐标得分
      - 确定长宽
        将feature map 通过另一个 1 x 1 conv， 得到 w x h x 2 的长宽dw, dh, 后续需要处理，因为 anchor 是相对于原始图片的：  
        $$
        w = \sigma * s * \exp(dw); h = \sigma * s * \exp(dh); 
        $$  
        通过上面两步可以得到 **anchor**
      - 特征适配
        传统情况需要做 ROIpooling 或者 ROIalign 进行尺度统一，但 GA 的 anchor 尺寸在各个位置都不一样，需要调整获得新的**特征图** 
        具体做法是将dw, dh 通过 1 x 1 卷积学习到信息给DeforConv
        ```python
        offset_channels = kernel_size * kernel_size * 2
        self.conv_offset = nn.Conv2d(
            2, deformable_groups * offset_channels, 1, bias=False)
        ```
      - 训练
        1. 损失函数加入坐标和长宽loss
        2. anchor位置训练: feature map 分为物体中心区域(CR), 忽略区域(IR)和外围区域(OR)，将 ground truth 对应在 feature map 上的区域标为物体中心区域，在训练的时候作为正样本，其余区域按照离中心的距离标为忽略或者负样本, FPN中多尺度，优先级 CR > IR > OR
        3. anchor 尺寸训练
        采样了9组尺寸，选取其中最大IoU的尺寸

   