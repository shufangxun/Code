### 2019.09.15



[TOC]

#### 1. **NMS & IOU 代码**
    ```python
    ## 获得顺序
    order = scores.argsort()[::-1]
    ...
    while order.size > 0:
        i = order[0]
        keep.append(i)
        ...
        ## 比较
        np.maximum(x1[i], x1[order[1:]])
        ...
        detlist = np.where(iou <= thr)[0]
        order = order[detlist + 1]

    ```


#### 2. **直方图均衡**  
   ```python
   ## 图片数组转换
   img = np.asarray(img)
   img = Image.fromarray(img)

   ## 统计灰度级别
   numpix = np.zeros([256])
   ...
   numpix[img[i][j]] += 1

   ## 累积归一化
   sumpix = np.zeros([256])
   ...
   sumpix[i] += sum(propix[:i])

   ## 重新映射  
   new_img = np.empty(img.shape, dtype=np.uint8)
   ...
   new_img[i][j] = 256 * sumpix[img[i][j]]

   ``` 



#### 3. **Guide Achoring**  
**是什么？**    

网络通过训练自动生成 anchor, 包括中心点 x,y 和 长宽 w,h, 无需预设  

**为什么？**   

因为预设的 anchor 尺寸和纵横比是固定的，无法适应极端情况，并且离散的尺寸和纵横比不利于学习，因此考虑让网络自己学习anchor  

**怎么做？**

1. 基于**条件分布**   
    $$p(x,y,w,h|I) = p(x,y|I)p(w,h|x,y,I)$$   

2. **先确定中心点，再预测长宽**  

    - **确定中心点**  
    将feature map 通过 1 x 1 conv + sigmoid, 得到 w x h x 1 的中心点坐标得分

    - **确定长宽**  
    将feature map 通过另一个 1 x 1 conv， 得到 w x h x 2 的长宽dw, dh, 后续需要处理，因为 anchor 是相对于原始图片的:  

        $$
        w = \sigma * s * \exp(dw); h = \sigma * s * \exp(dh); 
        $$    
通过上面两步可以得到 **anchor**  

3. **特征适配**  
    传统情况需要做 ROIpooling 或者 ROIalign 进行尺度统一，但 GA 的 anchor 尺寸在各个位置都不一样，需要调整获得新的**特征图**   

    具体做法是将dw, dh 通过 1 x 1 卷积学习到信息给DeforConv  
    ```python
    offset_channels = kernel_size * kernel_size * 2
    self.conv_offset = nn.Conv2d(
        2, deformable_groups * offset_channels, 1, bias=False)
    ```
**训练**  
- 损失函数加入坐标和长宽loss
- anchor位置训练: feature map 分为物体中心区域(CR), 忽略区域(IR)和外围区域(OR)，将 ground truth 对应在 feature map 上的区域标为物体中心区域，在训练的时候作为正样本，其余区域按照离中心的距离标为忽略或者负样本, FPN中多尺度，优先级 CR > IR > OR
- anchor 尺寸训练
采样了9组尺寸，选取其中最大IoU的尺寸


#### 4. **反向传播 & softmaxloss & 矩阵求导**  
   链式法则和维度匹配


#### 5. **mAP 的理解**
- 定义为PR曲线下的面积，综合Precision和Recall两个指标，评价模型优劣
- 遍历每一个点计算当前Recall下的Precision，注意TP只有一个，FP包含小于阈值和GT的多余框
 - COCO评估在不同的IoU[0.5:0.05:0.95]共10个IoU下的AP，并且在最后以这些阈值下的AP平均作为结果，记为mAP@[0.5, 0.95]
- VOC只评测了IOU=0.5下的AP值。因此相比VOC而言，COCO数据集的评测会更加全面：不仅评估到物体检测模型的分类能力，同时也能体现出检测模型的定位能力



#### 6. **Batch Norm**  
**训练和测试时的区别，以及如何在测试时加速**    
1. 训练的时候是以batch操作，计算方差和均值并滑动平均保留，学习两个参数$\gamma$和$\beta$，而测试阶段是一个样本，用保存的方差和均值测试  
2. 将Conv和BN融合，对卷积核进行一定的缩放，进行加速 
    [链接](https://zhuanlan.zhihu.com/p/48005099)

**为什么能起作用，解决了什么问题**
1. 解决了梯度消失问题
       层与层之间是关联的，但是每一层的数据分布是不一样的，这导致训练困难；并且反向传播过程中梯度的微小改变都将造成蝴蝶效应，所以运用BN将数据分布归一化，加快训练
2. 正则化作用
3. 学习率可以调大  

**不足之处** 

依赖于batchsize，当batchsize过小时，由于方差和均值都是训练阶段基于batchsize得到的（虽然可以滑动平均），不能体现数据的真实分布，导致训练，测试不统一



#### 7. **梯度下降算法VS拟牛顿法**  
- 梯度下降法是一阶导，拟牛顿法是二阶导
- 神经网络是大数据，高维度，非凸的，梯度下降法相比牛顿法更合适
    - 大数据中都是Batch处理，计算梯度（**一阶导**）引入了噪声，牛顿法（**二阶导**）噪声更大
    - 高维下Hessian矩阵计算复杂，而梯度下降是稀疏计算
    - 非凸时Hessian矩阵非正定，容易陷入**鞍点**
- 鞍点  
鞍点是梯度为0，但既不是极大值点也不是极小值点的临界点

#### 8. **解决创建环境时conda版本不匹配问题**  
`./bashrc`和` .bash_profile`区别：  
`./bashrc`每次bash shell被打开时,该文件被读取，` .bash_profile`登录时,该文件仅仅执行一次
```Shell
# 查看 .bashrc 和 .bash_profile
ls -a
# 查看文件大小  
du -h/-b
# 更改后生效
source ~/.bashrc
```

### **2019.09.16**
#### 1. 论文阅读

**《Optical spectrum feature analysis and recognition for optical network security with machine learning》**  

**摘要**  

论文针对侵入信号这一攻击类型，采用支持向量机和一维卷积，分析频谱数据，检测攻击，准确率达到98.54% 和 100% 

**三种攻击**  

窃听(eavesdropping)  
伪装攻击(masquerade attack):伪装成用户获得权限  
干扰攻击(jamming attack):阻止网络工作

**主体思想**

**网络状态隐藏在光学层参数中，**  
因此可以通过监视和分析物理层参数和性能来检测物理层攻击。 通过监测物理层参数（本文利用光谱），获得物理层损耗和参数，最后对网络安全环境进行分析，实现未授权信号的检测和识别。