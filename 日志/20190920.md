### **2019.09.20** 

- [**2019.09.20**](#20190920)
- [**1. 空洞卷积**](#1-空洞卷积)
- [**2. 感受野的计算**](#2-感受野的计算)
- [**3. DeeplabV3 ASPP **](#3-DeeplabV3-ASPP-)
- [**4. crossentropyloss，softmaxloss, softmax 梯度推导**](#4-crossentropylosssoftmaxloss-softmax-梯度推导)
- [**5. ROIpooling & ROIAlign**](#5-ROIpooling--ROIAlign)
  - [5.Tensor 转 numpy](#5Tensor-转-numpy)
  - [6.Linux相关](#6Linux相关)
  - [7.Mobilenet v1 & v2](#7Mobilenet-v1--v2)

### **1. 空洞卷积**

空洞卷积的为什么能增大感受野？为什么feature map不变小？优点？ 

**卷积核空洞**，变相增大了卷积核

- 不做池化，**维持高分辨率**（feature map不变）的同时增大感受野
  
- 没有**增加额外参数**，实际上卷积核还是3 x 3，只是卷积时每隔rate-1个像素点，未被计算的像素点权重为0

空洞卷积有什么问题？

**棋盘效应**，卷积后相邻像素点相关性不足

- 因为是空洞卷积的权重是稀疏的，这导致相邻像素点相关性不足，空洞率很大时，有效权重退化为中间一个点，无法捕获全局信息
  
- 解决方案是叠加多个空洞率的卷积+全局平均池化 

### **2. 感受野的计算**

$$
R_{n+1} = R_{n} + (K_{n+1}-1)\coprod_{i=1}^{n}S_{i}
$$

其中$R_{n}$是感受野尺寸，$K_{n}$是卷积核尺寸，$S$是滑动步长

### **3. DeeplabV3 ASPP **

**concate** : 1 x 1卷积 + 空洞率[6,12,18]的 3 x 3卷积 + GAP 后再 1 x 1卷积降维到256 

- 1 x 1 + BN:（512，h，w）-> (256, h, w)
- 3 x 3 [rate=6] + BN:（512，h，w）-> (256, h, w)
- 3 x 3 [rate=12] + BN:（512，h，w）-> (256, h, w)
- 3 x 3 [rate=18] + BN:（512，h，w）-> (256, h, w)
- GAP: （512，h，w）-> (512, 1, 1) 
- 1 x 1 + BN:（512，1，1）-> (256, 1, 1)
- upsample: （256，1，1）-> (256, h, w)concate + 1 x 1 + BN:  (1280, h, w) -> (256, h, w)

**代码**

```python
feature_map_h = feature_map.size()[2] # (== h/16)
feature_map_w = feature_map.size()[3] # (== w/16)
out_1x1 = F.relu(self.bn_conv_1x1_1(self.conv_1x1_1(feature_map))) # (shape: (batch_size, 256, h/16, w/16))
out_3x3_1 = F.relu(self.bn_conv_3x3_1(self.conv_3x3_1(feature_map))) # (shape: (batch_size, 256, h/16, w/16))
out_3x3_2 = F.relu(self.bn_conv_3x3_2(self.conv_3x3_2(feature_map))) # (shape: (batch_size, 256, h/16, w/16))
out_3x3_3 = F.relu(self.bn_conv_3x3_3(self.conv_3x3_3(feature_map))) # (shape: (batch_size, 256, h/16, w/16))

out_img = self.avg_pool(feature_map) # (shape: (batch_size, 512, 1, 1))
out_img = F.relu(self.bn_conv_1x1_2(self.conv_1x1_2(out_img))) # (shape: (batch_size, 256, 1, 1))
out_img = F.upsample(out_img, size=(feature_map_h, feature_map_w), mode="bilinear") # (shape: (batch_size, 256, h/16, w/16))

out = torch.cat([out_1x1, out_3x3_1, out_3x3_2, out_3x3_3, out_img], 1) # (shape: (batch_size, 1280, h/16, w/16))
out = F.relu(self.bn_conv_1x1_3(self.conv_1x1_3(out))) # (shape: (batch_size, 256, h/16, w/16))
out = self.conv_1x1_4(out) # (shape: (batch_size, num_classes, h/16, w/16))
```

**为什么要用全局平均池化？**

因为随着dilate rate变大，卷积核的有效权重变小，当rate=kernel size时，只剩中间的权重，退化为1x1卷积，没有捕获上下文信息

### **4. crossentropyloss，softmaxloss, softmax 梯度推导**
~

### **5. ROIpooling & ROIAlign** 

**ROIpooling**

经历两次量化，且都是最邻近插值，浮点型变为整型，损失精度

流程  
- 第一次量化

  将ROI映射到feature map对应的位置，**尺寸不是整数**，第一次量化

- 第二次量化

  将映射的ROI划分为如7*7的bins，因为不是整数，第二次量化

- 对每个bin内的像素点做maxpooling 

梯度传播  

在实际划分时，ROI中bin之间会有重叠，所以反向传播公式如下：
$$
\frac{\partial L}{\partial x_{i}} = \sum_{r}\sum_{j}[i = i^{*}(r,j)]\frac{\partial L}{\partial y_{r,j}}
$$  

- $y_{r,j}$是第$r$个ROI的第$j$个bin的值，$j$的范围是bin的个数，如$2 \times 2$，则$j=[0,3]$

- $i$是被第$r$个ROI的第$j$个bin选为最大值的索引


所以一个像素点可能被多个bin复用，同时多个ROI也会重叠，需要累加梯度。

第二次量化选取bin的代码
```python
# 划分区域
# ph、wh是输出bin的索引。[0,0],[0,1],[1,0],[1,1]
# 高度
start_ph(include)= floor（ph * roi_height / pooling_height）
end_ph(exclude) = ceil((ph + 1) * roi_height / pooling_height)
# 宽度
start_pw(include)= floor（pw * roi_width / pooling_width）
end_pw(exclude) = ceil((pw + 1) * roi_width / pooling_width)
```
比如对于第0个bin，索引是$[0,0]$，假设roi area为$5 \times 7$，pooling的目标是$2 \times 2$，则计算应该是：
```python
start_0h = floor(0 * 5 / 2) = 0
end_oh = ceil(1 * 5 / 2) = 3
start_0w = floor(0 * 7 / 2) = 0
end_0w = ceil(1 * 7 / 2) = 4
```
所以：
```python
pool[0] = [0,0] = maxpool[ROI[0:3, 0:4]]
pool[1] = [0,1] = maxpool[ROI[0:3, 3:7]]
pool[2] = [1,0] = maxpool[ROI[2:5, 0:4]]
pool[3] = [1,1] = maxpool[ROI[2:5, 3:7]]
```



ROI Align

不进行量化，而是通过双线性插值操作，保留了空间位置， 不损失精度

- 双线性插值是两个方向单线性插值的结合，可以先单线性找规律

流程
- 映射ROI到Feature map，但是不做量化，为浮点数
- 划分为多个bins，也不做量化，为浮点数
- 此时对于每一个bin
    - 平均划分为四个块，每一个小块取中间点坐标
    - 中间点坐标的像素值通过双线性插值获得
    - 四个中间点坐标做maxpooling作为bin的值

梯度传播    
$$ 
\frac{\partial L}{\partial x_{i}} = \sum_{r}\sum_{j}[d(i,i^{*}(r,j))< 1](1-\bigtriangleup h)(1-\bigtriangleup w)\frac{\partial L}{\partial y_{r,j}}
$$

相比ROI pooling，不同点在于：
- $i^{*}(r,j)$是浮点数位置坐标，和周围四个点都有关系，所以每一个与$i^{*}(r,j)$距离小于1的点都要接受梯度
- $\bigtriangleup w$和$\bigtriangleup h$是$i$和$i^{*}(r,j)$横纵坐标的差，作为双线性插值的系数，直观理解是离采样点越近，比重系数越大

#### 5.Tensor 转 numpy
```python
x = x.to(device)
outputs = model(x)
results = outputs.cpu().data.numpy()
```

#### 6.Linux相关

cp复制文件速度  

**结论**： 复制单一文件，如一个压缩文件夹，速度快；多个文件，如一个文件夹里很多文件，速度慢

**分析**：cp命令要把所有的文件地址变量都找到，然后读取内容，然后在另外的文件夹地址下开辟一块内存去储存文件内容。这就涉及到寻址,而寻址就是造成这种“出奇的慢”的原因

压缩文件
```python
    # 压缩：
    tar -zcvf archive_name.tar.gz filename
    # 解压：
    tar -zxvf archive_name.tar.gz
    # 解压缩到指定路径
    tar -zxvf archive_name.tar.gz -C new_dir
```

#### 7.Mobilenet v1 & v2

比较V1和V2  

V1 : 深度可分离卷积 + Relu6  
V2 : Inverse block + linear

Relu对于低维信息丢失大，在高维表现好，所以先升维度再做卷积，最后不用Relu，改为linear