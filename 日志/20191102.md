# 深度学习

## １．语义分割总结  

语义分割属于密集图像分类，因此既要很强的语义信息指导分类，又要很强的全局信息指导边界，这属于矛盾

## １.１．Unet

**Encoder-Decoder结构**：Encoder下采样提取语义信息，Decoder恢复全局信息  
**Skip connection:** 将语义信息和全局信息concat结合，指导分割

**下采样和上采样的优点**  
**下采样**: 降低运算量，增加感受野的大小，增强对图片的鲁棒性
**上采样**: 把语义特征再解码到原图的尺寸，最终得到分割结果

## １．２．DeeplabV3 & V3+

**空洞卷积**  
语义分割先下采样在上采样，会损失信息，并且下采样对于小样本会感知不到，因此提出空洞卷积  

**作用**：不降低feature map，增大感受野，让每个卷积输出都包含较大范围的信息  
**空洞卷积率$r$**：在两个卷积核之间插入$r-1$个0  
**空洞卷积核尺寸**：  
$$
K^{'} = K + (K-1)(r-1)
$$　

**缺点**：棋盘效应，空洞卷积是稀疏的，因此卷积后的feature map的相邻像素点缺乏相关性，损失了信息的连续性 ，特别是叠加多个相同空洞率时，有些像素点都没有参与计算　　

**解决方案**： ASPP叠加多个不同空洞率的卷积，但当空洞率太大时，有效卷积核会退化为1x1卷积，无法捕获全局信息，所以用全局平均池化

**DeeplabV3**  
ASPP结构，分为串联和并联，并联的效果更好：

- 一个**1×1**卷积和三个**3×3**的astrous rates={6,12,18}的空洞卷积，滤波器数量为256，卷积后包含BN层
- image-level特征，即做全局平均池化（为什么这么做？）
    因为随着dilate rate变大，卷积核的有效权重变小，当rate=kernel size时，只剩中间的权重，退化为1x1卷积，没有捕获上下文信息
- concat之后做**1x1**卷积

**DeeplabV3+**  
Unet思想结合到ASPP中，两次4倍上采样

- encoder-decoder结构，使用DeepLabv3作为encoder模块，并添加一个简单却有效的decoder模块
- 提出的encoder-decoder架构中，通过空洞卷积控制encoder特征的分辨率，用于平衡精度和运行时间
- 将Xception作为backbone，在ASPP和decoder模块中加入深度可分离卷积

