


### **2019.09.18**
- [**2019.09.18**](#20190918)
  - [1.百面机器学习](#1百面机器学习)
  - [**特征工程**](#特征工程)
  - [**降维**](#降维)
  - [**采样**](#采样)
  - [**模型评估**](#模型评估)
  
#### 1.百面机器学习

#### **特征工程**

- 特征归一化的目的

  为了统一量纲，有利于训练，比如梯度下降，注意这对决策树无效，因为是以信息增益为指标

- 数据不足的处理方式

  数据不足会导致过拟合，所以需要正则化，数据增强，dropout，模型集成

#### **降维**

- 为什么需要降维

  数据在高维冗余，如三维空间上的一个平面，在合适的坐标变化下可以在二维空间上清晰表示，所以需要降到低维。

- 降维和特征提取的区别

  降维是在低维生成新的有代表性的特征；特征提取是按照重要性选择特征

- PCA介绍

  无监督降维，基于最大方差(最小投影距离)，要先**数据归一化**，然后计算协方差，求协方差的特征值和特征向量，选取占比最大的几个  

- LDA介绍

  有监督降维，基于类间方差最大和类内方差最小，解决PCA的类别划分不清楚问题

- PCA和LDA应用场景  

  PCA是无监督降维，不会考虑类别，而LDA是考虑类别的，比如在语言识别时，先用PCA去掉固定的噪声，然后用LDA，区分每一个人的声音

#### **采样**

- 采样的目的

  以少量的数据表征真实分布，比如训练集就是为了在训练时表征真实样本情况

- 正负样本不平衡时如何采样

  正负样本不均衡会导致训练和测试时数据分布不一，影响模型性能，可以采用过采样和欠采样。过采样是对少量样本复制，这会导致过拟合，欠采样是丢弃多数样本，这会丢失有用信息

- 改进的采样

  Smote，Balance Cascade

#### **模型评估**

- 为何要模型评估

  只有选择与问题相匹配的方法，才能快速发现模型的不足，迭代更新

- 准确率、精确率、召回率

  **准确率** ：正确分类的样本占总样本的比例，在不同类样本不平衡时，模型倾向于分类到多数样本上，因为这样做损失小，在类别不平衡时，采用平均类别准确率  

  **精确率**：TP / (TP+FP)

  **召回率**：TP / (TP+FN)
  
- Top N

  将置信度前N的样本判断为正样本，计算Precision和Recall

- ROC 和 P-R曲线

  ROC对正负样本不均衡稳定，因为是基于TPR和FPR

- AUC的计算

  复杂度低的方法要会

- 过拟合和欠拟合
