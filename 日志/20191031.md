# 1. 深度学习

## 1.1 Diceloss

Diceloss
应用于图像分割，直接用来优化评价指标，实际上主要还是靠BCE优化，可以加权到BCE中
$$
Diceloss = 1 - \frac {2|X \cap Y|}{|X| + |Y|}
$$
分子可以两个矩阵点乘后统计1数目等价，分母分别统计两个矩阵中1数目

```python
def forward(self, output, target):
        inter = 2 * (torch.sum(output * target) + self.smooth)
        union = torch.sum(output) + torch.sum(target) + self.smooth + self.eps
        return 1 - inter / union
```

## 1.2 优化器总结

符号和框架  
学习率$α$、动量参数$β$、动量$v$、权重$w$、目标函数：$f(w)$

在epoch $t$  ：
1. 计算目标函数关于当前参数的梯度：
   $g_{t} =\bigtriangledown  f(w_{t})$
2. 计算一阶动量和二阶动量：  
   $v_{t} = \phi(g_{1},g_{2},...)$  
   $s_{t} = \psi(g_{1},g_{2},...)$
3. 计算当前时刻的下降梯度：   
   $\eta_{t} =  \alpha\frac{v_{t}}{\sqrt{s_{t}}}$
4. 根据下降梯度进行更新：  
   $w_{t+1} = w_{t} - \eta_{t}$

**SGD**  
SGD没有动量的概念，也就是：  
$$v_{t}=g_{t},s_{t}=I$$  
则梯度下降更新为:  
$$w_{t+1} = w_{t} - \alpha g_{t}$$

SGD的缺点是下降速度慢，而且可能会在沟壑的两边持续震荡，停留在一个局部最优点

**SGD with Momentum**  
为了抑制振荡，在一阶动量中加入惯性：
$$
v_{t}=\beta v_{t-1} + (1-\beta)g_{t}, s_{t}=I
$$
则梯度下降更新为:  
$$
w_{t+1} = w_{t} - \alpha v_{t}
$$

**RMSdrop**  
计算二阶动量，让惯性慢一点：
$$
s_{t}=\beta s_{t-1} + (1-\beta)g_{t}^{2}, v_{t}=g_{t}
$$
则梯度下降更新为:  
$$
w_{t+1} = w_{t} - \alpha \frac{g_{t}}{\sqrt{s_{t}}}
$$  

**Adam**  
把一阶动量和二阶动量结合，Adaptive + Momentum
$$
s_{t}=\beta_{1} s_{t-1} + (1-\beta_{1})g_{t}^{2}, v_{t}=\beta_{2} v_{t-1} + (1-\beta_{2})g_{t}
$$
则梯度下降更新为:  
$$
w_{t+1} = w_{t} - \alpha \frac{v_{t}}{\sqrt{s_{t}}}
$$  

**总结**：一阶动量改变梯度，二阶动量改变学习率

## 1.3 NMS相关

IoU计算

**xyxy**

```python
def iou(box1, box2):
    '''
    box [x1,y1,x2,y2]
    '''
    xx1 = max(box1[0], box2[0])
    yy1 = max(box1[1], box2[1])
    xx2 = min(box1[2], box2[2])
    yy2 = min(box1[3], box2[3])

    box1Area = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1)
    box2Area = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1)

    inter = max(xx2 - xx1 + 1, 0.0) * max(yy2 - yy1 + 1, 0.0)
    union = box1Area + box2Area - inter

    iou = inter / union

    return iou
```

**xywh**

```python
def iou(x1,y1,w1,h1,x2,y2,w2,h2):
    up = min(y1 + h1 / 2, y2 + h2 /2)
    down =  max(y1 - h1 / 2, y2 + h2 / 2)
    right = min(x1 + w1 / 2, x2 + w2 /2)
    left = max(x1 - w1 / 2, x2 - w2 / 2)

    if up > down and right > left:
        inter = (up - down) * (right - lefy)
        union = w1 * h1 + w2 * h2 - intersetion
        return inter / union
    else:
        return 0
```

找到置信度高的框，去除重叠框

- 根据置信度排序，选取当前最大得分框
- 计算剩余框与当前框的IoU，去除IoU大于阈值的框
- 然后重复上面步骤

```python
import numpy as np

def nms(dets, thr=0.5):
    '''
    dets: (N,5) 
    前四个维度是(x,y),最后一个维度是score
    只对一个类别做NMS
    '''
    xl = dets[:,0]
    yl = dets[:,1]
    xr = dets[:,2]
    yr = dets[:,3]
    score = dets[:,4]

    order = score.argsort()[::-1]   # box按socre降序的索引  
    area = (xr - xl + 1) * (yr - yl + 1) # 所有box的面积数组
    keep = [] # 保留的索引

    while order.size > 0:
        i = order[0]
        keep.append(i)
        # box的交集
        xxl = np.maximum(xl[i], xl[order[1:]])  # 数组
        yyl = np.maximum(yl[i], yl[order[1:]])
        xxr = np.minimum(xl[i], xl[order[1:]])
        yyr = np.minimum(xl[i], xl[order[1:]])

        inter = np.maximum(0.0, xxr - xxl + 1) * np.maximum(0.0, yyr - yyl + 1)
        union = area[i] + area[order[1:]] - inter  # 数组 广播机制
        iou = inter / union # 数组

        idx_list = np.where(iou <= thr)[0]
        order = order[idx_list + 1]

    return dets[keep]
```


## 1.4 ResNexth和分组卷积

**范式**： split-transform-merge  
**结构**：分组卷积

- 1 x 1卷积将128通道分为32个4通道
- 对4通道分别做3x3卷积操作  分支同构
- 再聚合做1x1卷积

**优势**

- 参数量未变下效果更好，代价是运行时间久一点(过多的分组卷积操作会增大MAC，从而使模型速度变慢)
- 分支同构，模型简单

**分组卷积有效性分析**

- 卷积未出现之时，是全连接操作，每一个神经元都和前面所有神经元有关
- 后来发现图像的局部相关性，利用卷积－局部相关和权重共享，在三个维度上操作
    1. **所有channel**
    2. 局部ｗ和ｈ
- 卷积对所有通道操作，也可能是一种信息浪费。不同的卷积参数会产生不同的卷积效果，因而在不同的通道中，最终的输出结果也有所不同
- 因此考虑通道的局部相关性，将输入数据channel分为多组，分别做卷积，再拼接

## 1.5 Flops和parameters

**定义**  
Flops: floating point operations，指浮点运算数，可作为计算量，与输入的Feature map有关  
Parameters: 卷积层的参数，与输入无关

**Flops**计算
> n个数相加计算量n-1  
> n个数相乘计算量n

设 $C_{i}$ 和 $C_{o}$ 分别是输入输出channel，$HW$是输出层Feature map，$K$是卷积核尺寸，卷积核Flops:
$$
(2 \cdot C_{i} \cdot K^{2} - 1) \cdot HW \cdot C_{o}
$$

可以分为两步， $(2 \cdot C_{i} \cdot K^{2} - 1) =  (C_{i} \cdot K^{2}) +  (C_{i} \cdot K^{2} - 1)$ ，第一项是乘法运算数，第二项是加法运算数，因为n个数相加，要加n-1次，所以不考虑bias，会有一个-1；如果考虑bias，刚好中和掉，括号内变为 $(2 \cdot C_{i} \cdot K^{2} )$

全连接层Flops：$(2 \cdot I - 1 )\cdot O$

**Parameters**　　
就是简单的卷积核参数计算$C_{i}, C_{o}, K$　　
$$
Para = C_{i} \cdot K^{2} \cdot C_{o}
$$

**Flops和Parameter关系**  
参数和输入无关，Flops和参数有关系
